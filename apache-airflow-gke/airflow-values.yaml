---
executor: CeleryExecutor # for scale, make sure redis is enabled
airflowHome: /opt/airflow
# Fernet key settings
# Note: fernetKey can only be set during install, not upgrade
fernetKey: ~
fernetKeySecretName: ~
useStandardNaming: true # to follow fullname template

# Flask secret key for Airflow Webserver: `[webserver] secret_key` in airflow.cfg
webserverSecretKey: ~
webserverSecretKeySecretName: ~

extraEnvFrom: |
  - secretRef:
      name: 'airflow-secrets'

dags:
  # Where dags volume will be mounted. Works for both persistence and gitSync.
  # If not specified, dags mount path will be set to $AIRFLOW_HOME/dags
  persistence:
    enabled: false

  gitSync:
    enabled: false

# Ingress configuration
ingress:
  # Enable all ingress resources (deprecated - use ingress.web.enabled and ingress.flower.enabled)
  enabled: ~

  # Configs for the Ingress of the web Service
  web:
    # Enable web ingress resource
    enabled: false

logs:
  persistence:
    enabled: false
    size: 5Gi

triggerer:
  enabled: true
  replicas: 1
  serviceAccount:
    create: false

workers:
  replicas: 1
  persistence:
    enabled: false
  serviceAccount:
    create: false

scheduler:
  enabled: true
  replicas: 1
  serviceAccount:
    create: false

webserver:
  enabled: true
  replicas: 1
  serviceAccount:
    create: false

kerberos:
  enabled: false

flower:
  enabled: false

statsd:
  enabled: true

# Configuration for the redis provisioned by the chart
redis:
  enabled: true
  terminationGracePeriodSeconds: 600
  persistence:
    enabled: true
    size: 1Gi

  resources: {}
  #  limits:
  #   cpu: 100m
  #   memory: 128Mi
  #  requests:
  #   cpu: 100m
  #   memory: 128Mi

  # If set use as redis secret. Make sure to also set data.brokerUrlSecretName value.
  passwordSecretName: ~

  # Else, if password is set, create secret with it,
  # Otherwise a new password will be generated on install
  # Note: password can only be set during install, not upgrade.
  password: ~

  # This setting tells kubernetes that its ok to evict
  # when it wants to scale a node down.
  safeToEvict: true

  # Set to 0 for backwards-compatiblity
  uid: 0

  # Auth secret for a private registry
# This is used if pulling airflow images from a private registry
registry:
  secretName: ~ # NOTE: overwrite
  # Example:
  # connection:
  #   user: ~
  #   pass: ~
  #   host: ~
  #   email: ~
  connection: {}

# Elasticsearch logging configuration
elasticsearch:
  # Enable elasticsearch task logging
  enabled: false
  # A secret containing the connection
  secretName: ~
  # Or an object representing the connection
  # Example:
  # connection:
  #   scheme: ~
  #   user: ~
  #   pass: ~
  #   host: ~
  #   port: ~
  connection: {}

# All ports used by chart
ports:
  flowerUI: 5555
  airflowUI: 8080
  workerLogs: 8793
  triggererLogs: 8794
  redisDB: 6379
  statsdIngest: 9125
  statsdScrape: 9102
  pgbouncer: 6543
  pgbouncerScrape: 9127
  # rpcServer support is experimental / dev purpose only and will later be renamed
  _rpcServer: 9080

# Define any ResourceQuotas for namespace
quotas: {}

# Define default/max/min values for pods and containers in namespace
limits: []

# This runs as a CronJob to cleanup old pods.
cleanup:
  enabled: false

# Not recommended for production
postgresql:
  enabled: true
  auth:
    enablePostgresUser: true
    postgresPassword: postgres
    username: ""
    password: ""

pgbouncer:
  enabled: true
  # The maximum number of connections to PgBouncer
  maxClientConn: 100
  # The maximum number of server connections to the metadata database from PgBouncer
  metadataPoolSize: 10
  # The maximum number of server connections to the result backend database from PgBouncer
  resultBackendPoolSize: 5

# yamllint disable rule:line-length
config:
  core:
    dags_folder: '{{ include "airflow_dags" . }}'
    # This is ignored when used with the official Docker image
    load_examples: "False"
    executor: "{{ .Values.executor }}"
    # For Airflow 1.10, backward compatibility; moved to [logging] in 2.0
    colored_console_log: "True"
    remote_logging: '{{- ternary "True" "False" .Values.elasticsearch.enabled }}'
    base_url: "http://airflow-webserver:8080"
  logging:
    remote_logging: '{{- ternary "True" "False" .Values.elasticsearch.enabled }}'
    colored_console_log: "True"
  metrics:
    statsd_on: '{{ ternary "True" "False" .Values.statsd.enabled }}'
    statsd_port: 9125
    statsd_prefix: airflow
    statsd_host: '{{ printf "%s-statsd" (include "airflow.fullname" .) }}'
  api:
    auth_backends: airflow.api.auth.backend.basic_auth
    access_control_allow_headers: "origin, content-type, accept"
    access_control_allow_methods: "POST, GET, OPTIONS, DELETE"
    access_control_allow_origins: "*"
  webserver:
    enable_proxy_fix: "True"
    expose_config: "True"
    # For Airflow 1.10
    rbac: "True"
  celery:
    flower_url_prefix: '{{ ternary "" .Values.ingress.flower.path (eq .Values.ingress.flower.path "/") }}'
    worker_concurrency: 16
  scheduler:
    standalone_dag_processor: '{{ ternary "True" "False" .Values.dagProcessor.enabled }}'
    # statsd params included for Airflow 1.10 backward compatibility; moved to [metrics] in 2.0
    statsd_on: '{{ ternary "True" "False" .Values.statsd.enabled }}'
    statsd_port: 9125
    statsd_prefix: airflow
    statsd_host: '{{ printf "%s-statsd" (include "airflow.fullname" .) }}'
    # `run_duration` included for Airflow 1.10 backward compatibility; removed in 2.0.
    run_duration: 41460
  elasticsearch:
    json_format: "True"
    log_id_template: "{dag_id}_{task_id}_{execution_date}_{try_number}"
  elasticsearch_configs:
    max_retries: 3
    timeout: 30
    retry_timeout: "True"
  kerberos:
    keytab: "{{ .Values.kerberos.keytabPath }}"
    reinit_frequency: "{{ .Values.kerberos.reinitFrequency }}"
    principal: "{{ .Values.kerberos.principal }}"
    ccache: "{{ .Values.kerberos.ccacheMountPath }}/{{ .Values.kerberos.ccacheFileName }}"
  celery_kubernetes_executor:
    kubernetes_queue: "kubernetes"
  # The `kubernetes` section is deprecated in Airflow >= 2.5.0 due to an airflow.cfg schema change.
  # The `kubernetes` section can be removed once the helm chart no longer supports Airflow < 2.5.0.
  kubernetes:
    namespace: "{{ .Release.Namespace }}"
    # The following `airflow_` entries are for Airflow 1, and can be removed when it is no longer supported.
    airflow_configmap: '{{ include "airflow_config" . }}'
    airflow_local_settings_configmap: '{{ include "airflow_config" . }}'
    pod_template_file: '{{ include "airflow_pod_template_file" . }}/pod_template_file.yaml'
    worker_container_repository: "{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}"
    worker_container_tag: "{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}"
    multi_namespace_mode: '{{ ternary "True" "False" .Values.multiNamespaceMode }}'
  # The `kubernetes_executor` section duplicates the `kubernetes` section in Airflow >= 2.5.0 due to an airflow.cfg schema change.
  kubernetes_executor:
    namespace: "{{ .Release.Namespace }}"
    pod_template_file: '{{ include "airflow_pod_template_file" . }}/pod_template_file.yaml'
    worker_container_repository: "{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}"
    worker_container_tag: "{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}"
    multi_namespace_mode: '{{ ternary "True" "False" .Values.multiNamespaceMode }}'
  triggerer:
    default_capacity: 1000
# yamllint enable rule:line-length
